## ğŸš¨ Intrusion Detection System using Machine Learning
A multi-model intrusion detection system built on the **NSL-KDD dataset**. This project includes end-to-end data preprocessing, feature engineering, training multiple ML models (Random Forest, ANN, etc.), saving model pipelines, and deploying the final model using **Streamlit** for real-time inference.

---

## ğŸ“ Project Structure

```
intrusion-detection-multimodel/
â”‚
â”œâ”€â”€ app.py                            # Streamlit web app
â”œâ”€â”€ requirements.txt                  # Project dependencies
â”œâ”€â”€ sample_input_original.csv        # Sample test input for app
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ final_rf_model.pkl           # Trained Random Forest model
â”‚   â”œâ”€â”€ final_scaler.pkl             # StandardScaler object
â”‚   â”œâ”€â”€ final_encoders.pkl           # LabelEncoders for categorical cols
â”‚   â””â”€â”€ final_label_encoder.pkl      # LabelEncoder for labels
â”‚
â”œâ”€â”€ data/
â”‚       â”œâ”€â”€ X_train.csv
â”‚       â”œâ”€â”€ X_val.csv
â”‚       â”œâ”€â”€ y_train.csv
â”‚       â””â”€â”€ y_val.csv
â”‚
â””â”€â”€ notebooks/
    â””â”€â”€ 08_Streamlit_Web_App_Preparation.ipynb
```

---

## ğŸ“Š Dataset

* **NSL-KDD Dataset**
* Cleaned and preprocessed from original version.
* Features include: protocol type, service, flag, count features, host-based metrics, etc.

---

## ğŸ”§ Steps Followed

### âœ… 1. Data Preprocessing

* Label encoded: `protocol_type`, `service`, `flag`
* Normalized numeric features using `StandardScaler`
* Encoded label: `normal` â†’ 1, `attack` â†’ 0
* Split into train/test and saved to `data/processed/`

### âœ… 2. Model Training

* Trained multiple models including:

  * Random Forest âœ…
  * ANN (Keras)
  * Logistic Regression, SVM (optional)
* Random Forest chosen for best balance between accuracy & simplicity
* Saved model and preprocessing artifacts using `joblib`

### âœ… 3. Model Saving

* `final_rf_model.pkl`
* `final_scaler.pkl`
* `final_encoders.pkl`
* `final_label_encoder.pkl`

### âœ… 4. Streamlit Web App

* Allows users to upload CSV files (no label column)
* Predicts whether network traffic is **normal** or an **intrusion**
* Displays result in tabular format

---

## ğŸš€ Run the Web App

### ğŸ”¹ Local Setup
1. Install dependencies:
pip install -r requirements.txt
2. Run app locally:
streamlit run app.py
3. Go to browser:
http://localhost:8501
```

### ğŸ”¹ Upload File Example

Use the `sample_input_original.csv` file included in the repo to test the app.

ğŸ“Œ **Note:** Ensure uploaded file has **same schema** as `X_train.csv` (after preprocessing but before encoding/scaling).

---

## ğŸ›† Deployment

Successfully deployed on **Streamlit Cloud**. Ensure:

* All `.pkl` and `.csv` files are committed to GitHub
* `requirements.txt` is included
* `app.py` is in root directory

---

## ğŸ“š Requirements

Generated via `pip freeze`:

```
streamlit
pandas
numpy
scikit-learn
joblib
```

---

## ğŸ§ Model Info

| Metric       | Value                             |
| ------------ | --------------------------------- |
| Accuracy     | \~99%                             |
| Model        | Random Forest                     |
| Dataset      | NSL-KDD                           |
| Input Format | Preprocessed CSV with 41 features |

---

## ğŸ‘¨â€ğŸ’» Author

* **Sanchay Chauhan**
* GitHub: [Sanchay987](https://github.com/Sanchay987)
